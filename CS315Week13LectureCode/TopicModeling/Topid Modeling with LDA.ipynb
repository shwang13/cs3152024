{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99d9730-5978-4399-b192-6cfe73bd78a8",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA\n",
    "\n",
    "This tutorial shows how to perform LDA topic modeling using the `sklearn`. It uses different functions to explore the topics and the documents. It is using a small dataset from the NYT articles to keep the interpretation manageable. \n",
    "\n",
    "There are **a few scattered activities for you** in the notebook.\n",
    "\n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Load the data](#sec1)  \n",
    "2. [Convert to document-term matrix](#sec2)  \n",
    "3. [Fit the LDA model and explore it](#sec3)\n",
    "4. [Finding the most optimal number of topics with GridSearch](#sec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6bd4b-cf18-48eb-978e-b4a1933cc4ef",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## 1. Load the data\n",
    "\n",
    "I used the NYT API to get all articles from March 2024. Then, I combined together the fields \"snippet\" and \"lead_paragraph\" to create a longer document for each article. Then, I chose the articles for the section_name: food, realestate, and science. I saved the documents only into a json file. \n",
    "\n",
    "Below there is a function that will read a JSON file and turn it into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639a2fcd-bf16-4e30-bf5a-2c6657f74135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shhwa\\AppData\\Local\\Temp\\ipykernel_14520\\2317910270.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def jsonToDF(name):\n",
    "    \"\"\"Read a list of sentences from the JSON file, store them in a dataframe\"\"\"\n",
    "    \n",
    "    with open(f\"{name}.json\") as fin:\n",
    "        textList = json.load(fin)\n",
    "\n",
    "    # create a name for each document, based on its category\n",
    "    indexNames = [f\"{name}_{i+1}\" for i in range(len(textList))]\n",
    "\n",
    "    # create the dataframe, it will have one column and one index\n",
    "    df = pd.DataFrame(data=textList, index=indexNames)\n",
    "    df.columns = ['document']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1c82-168e-4c85-81a9-8d8aee69189e",
   "metadata": {},
   "source": [
    "First, let's read the content of all three files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b054e82-8fb4-48d8-8097-58901204094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = jsonToDF(\"food\")\n",
    "realestate = jsonToDF(\"realestate\")\n",
    "science = jsonToDF(\"science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ba486-53d4-42ca-a9d6-b8d83421e6b5",
   "metadata": {},
   "source": [
    "Check one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148e94b7-af45-4b55-9688-b72f0b23df10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food_1</th>\n",
       "      <td>Commit this method to memory for caramelized a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_2</th>\n",
       "      <td>Kenji López-Alt’s buttery, unabashedly garlick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_3</th>\n",
       "      <td>Just add rice or potatoes (and maybe a chilled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_4</th>\n",
       "      <td>It’s a showstopping kaleidoscope of bulgogi, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_5</th>\n",
       "      <td>In the third installment of her YouTube series...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 document\n",
       "food_1  Commit this method to memory for caramelized a...\n",
       "food_2  Kenji López-Alt’s buttery, unabashedly garlick...\n",
       "food_3  Just add rice or potatoes (and maybe a chilled...\n",
       "food_4  It’s a showstopping kaleidoscope of bulgogi, s...\n",
       "food_5  In the third installment of her YouTube series..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85289d1-577b-4d9a-85f6-db78954b3a73",
   "metadata": {},
   "source": [
    "Check the shape of each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3120885-38f3-4247-ae18-6cdee1f8621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food: (81, 1)\n",
      "realestate: (82, 1)\n",
      "science: (71, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"food:\", food.shape)\n",
    "print(\"realestate:\", realestate.shape)\n",
    "print(\"science:\", science.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731de53-159f-4efb-90ef-0ea27a34c22e",
   "metadata": {},
   "source": [
    "Let's concatenate all of them in a single dataframe for the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9832bd85-1daa-4e32-b1c2-fff04095068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDocs = pd.concat([food, realestate, science])\n",
    "allDocs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63d4de4-91bf-4f62-b496-b24f9f176e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food_1</th>\n",
       "      <td>Commit this method to memory for caramelized a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_2</th>\n",
       "      <td>Kenji López-Alt’s buttery, unabashedly garlick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_3</th>\n",
       "      <td>Just add rice or potatoes (and maybe a chilled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_4</th>\n",
       "      <td>It’s a showstopping kaleidoscope of bulgogi, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_5</th>\n",
       "      <td>In the third installment of her YouTube series...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 document\n",
       "food_1  Commit this method to memory for caramelized a...\n",
       "food_2  Kenji López-Alt’s buttery, unabashedly garlick...\n",
       "food_3  Just add rice or potatoes (and maybe a chilled...\n",
       "food_4  It’s a showstopping kaleidoscope of bulgogi, s...\n",
       "food_5  In the third installment of her YouTube series..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4079738-7315-4852-b1d0-5d933048e54f",
   "metadata": {},
   "source": [
    "Make the column wide enough to show all text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8aaaef3-cb3c-4ff2-a8a7-5194215f3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac1164-c4df-4036-abdf-429616b8c2f6",
   "metadata": {},
   "source": [
    "Look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0532f308-7688-494d-95cc-e64137c4ccaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food_1</th>\n",
       "      <td>Commit this method to memory for caramelized and crisp yet tender vegetables all year long. The kindest thing you can do for yourself when you’re stiff from being in the cold is to find some warmth: Because as the chill in your bones starts to fade, so does your stiffness. The same thing happens to hard winter vegetables when they’re enveloped in the heat of the oven — they soften and sweeten as they roast until they’re golden outside and tender in the middle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_2</th>\n",
       "      <td>Kenji López-Alt’s buttery, unabashedly garlicky noodles are as easy to make as they are to devour. Good morning. The vernal equinox is in less than three weeks, but you wouldn’t know it from the frosted mud in the woods and the storm-wounded lawns where I stay. It’s bare ugly everywhere save in the bays, where water clear as gin flows over rocks in a spectrum of pink. At the market: cabbage and potatoes, a box of turnips, industrial berries that might have been grown in space. The new season’s coming, sure as tulips, but right now it’s hard to imagine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_3</th>\n",
       "      <td>Just add rice or potatoes (and maybe a chilled white wine). Citrus and salmon is a winning combination, previously proven in New York Times Cooking’s recipes for broiled salmon with mustard and lemon, roasted salmon with ginger-lime butter and citrusy roasted salmon and potatoes. Our newest addition to this esteemed company is Farideh Sadeghin’s recipe for orange-glazed baked salmon. It’s a no-fuss fish dinner with a clever, timesaving twist: Farideh builds a side salad into the recipe by tossing salad greens with some of the reserved honeyed orange juice that is used to flavor the salmon. If you’re looking at the above image and thinking, “I bet blood oranges would be especially beautiful and excellent in this recipe,” know that Coco, a reader, already tried that and can confirm that the results were “absolutely delicious.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_4</th>\n",
       "      <td>It’s a showstopping kaleidoscope of bulgogi, shiitakes, bean sprouts, spinach, carrots and cucumbers, all drizzled with a spicy gochujang sauce. Good morning. On Sunday, I like a project in the kitchen more than on any other day. It’s a chance to work at the stove without the need to get something on the table in 45 minutes, a time to stretch my skill set. Mostly, it’s an opportunity to explore recipes rather than simply following them. On Sundays I don’t want to fly by wire. I want to fly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_5</th>\n",
       "      <td>In the third installment of her YouTube series, the cookbook author and chef Sohla El-Waylly will teach you how to master the basics of the bird. For beginners and experienced cooks alike, preparing chicken can come with a lot of questions (and nerves!). Am I going to get salmonella? How do I butcher a whole bird? Am I doomed to an eternity of dry breast meat? In the third installment of her YouTube series, Cooking 101, the chef and cookbook author Sohla El-Waylly will help you master the basics of the bird, then set you up with a handful of recipes that highlight white and dark meat.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    document\n",
       "food_1                                                                                                                                                                                                                                                                                                                                                                                      Commit this method to memory for caramelized and crisp yet tender vegetables all year long. The kindest thing you can do for yourself when you’re stiff from being in the cold is to find some warmth: Because as the chill in your bones starts to fade, so does your stiffness. The same thing happens to hard winter vegetables when they’re enveloped in the heat of the oven — they soften and sweeten as they roast until they’re golden outside and tender in the middle.\n",
       "food_2                                                                                                                                                                                                                                                                                        Kenji López-Alt’s buttery, unabashedly garlicky noodles are as easy to make as they are to devour. Good morning. The vernal equinox is in less than three weeks, but you wouldn’t know it from the frosted mud in the woods and the storm-wounded lawns where I stay. It’s bare ugly everywhere save in the bays, where water clear as gin flows over rocks in a spectrum of pink. At the market: cabbage and potatoes, a box of turnips, industrial berries that might have been grown in space. The new season’s coming, sure as tulips, but right now it’s hard to imagine.\n",
       "food_3  Just add rice or potatoes (and maybe a chilled white wine). Citrus and salmon is a winning combination, previously proven in New York Times Cooking’s recipes for broiled salmon with mustard and lemon, roasted salmon with ginger-lime butter and citrusy roasted salmon and potatoes. Our newest addition to this esteemed company is Farideh Sadeghin’s recipe for orange-glazed baked salmon. It’s a no-fuss fish dinner with a clever, timesaving twist: Farideh builds a side salad into the recipe by tossing salad greens with some of the reserved honeyed orange juice that is used to flavor the salmon. If you’re looking at the above image and thinking, “I bet blood oranges would be especially beautiful and excellent in this recipe,” know that Coco, a reader, already tried that and can confirm that the results were “absolutely delicious.”\n",
       "food_4                                                                                                                                                                                                                                                                                                                                                       It’s a showstopping kaleidoscope of bulgogi, shiitakes, bean sprouts, spinach, carrots and cucumbers, all drizzled with a spicy gochujang sauce. Good morning. On Sunday, I like a project in the kitchen more than on any other day. It’s a chance to work at the stove without the need to get something on the table in 45 minutes, a time to stretch my skill set. Mostly, it’s an opportunity to explore recipes rather than simply following them. On Sundays I don’t want to fly by wire. I want to fly.\n",
       "food_5                                                                                                                                                                                                                                                       In the third installment of her YouTube series, the cookbook author and chef Sohla El-Waylly will teach you how to master the basics of the bird. For beginners and experienced cooks alike, preparing chicken can come with a lot of questions (and nerves!). Am I going to get salmonella? How do I butcher a whole bird? Am I doomed to an eternity of dry breast meat? In the third installment of her YouTube series, Cooking 101, the chef and cookbook author Sohla El-Waylly will help you master the basics of the bird, then set you up with a handful of recipes that highlight white and dark meat."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b8a22b-5265-4fb5-b49e-b22ae8f82eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>science_67</th>\n",
       "      <td>Dr. Goodall, who is best known for her work with chimpanzees, recently celebrated her forthcoming 90th birthday with as many dogs and explained why she isn’t slowing down. Jane Goodall is turning 90 on April 3 and the primatologist-turned-activist seems busier than ever. This year, she’ll be on the road for 320 days. She’ll be raising money for her nonprofit organizations, the Jane Goodall Institute and Roots &amp; Shoots, and encouraging people to take environmental action.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science_68</th>\n",
       "      <td>How do champion skaters accomplish their extraordinary jumps and spins? Brain science is uncovering clues.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science_69</th>\n",
       "      <td>The Delta IV Heavy, a rocket that briefly bursts into flame just before it lifts off, is set to launch for the last time soon. The ignition of the Delta IV Heavy rocket is perhaps the most visually striking liftoff you’ll ever see — the rocket seemingly burns itself up on the launchpad before it heads to space. Now, the very last Delta IV Heavy ever is on the launchpad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science_70</th>\n",
       "      <td>A device called LightSound is being distributed to help the blind and visually impaired experience this year’s event. On Aug. 21, 2017, Kiki Smith’s teenage sons giddily prepared to watch the partial solar eclipse in Rochester, N.Y. As Ms. Smith listened to their chatter, she felt excluded.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science_71</th>\n",
       "      <td>The rendezvous between the sun and the moon in 2017 captivated a small region in the Midwest. Lucky for Americans at the eclipse crossroads, they get to see it again. It is rare for a total solar eclipse to hit the same place twice — once every 366 years on average. In 2019, this happened in the Pacific Ocean, far west of the coast of Chile. By a stroke of luck, the next one will span a region of about 10,000 square miles that includes parts of southern Illinois, southeastern Missouri and western Kentucky.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   document\n",
       "science_67                                      Dr. Goodall, who is best known for her work with chimpanzees, recently celebrated her forthcoming 90th birthday with as many dogs and explained why she isn’t slowing down. Jane Goodall is turning 90 on April 3 and the primatologist-turned-activist seems busier than ever. This year, she’ll be on the road for 320 days. She’ll be raising money for her nonprofit organizations, the Jane Goodall Institute and Roots & Shoots, and encouraging people to take environmental action.\n",
       "science_68                                                                                                                                                                                                                                                                                                                                                                                                                      How do champion skaters accomplish their extraordinary jumps and spins? Brain science is uncovering clues. \n",
       "science_69                                                                                                                                             The Delta IV Heavy, a rocket that briefly bursts into flame just before it lifts off, is set to launch for the last time soon. The ignition of the Delta IV Heavy rocket is perhaps the most visually striking liftoff you’ll ever see — the rocket seemingly burns itself up on the launchpad before it heads to space. Now, the very last Delta IV Heavy ever is on the launchpad.\n",
       "science_70                                                                                                                                                                                                                              A device called LightSound is being distributed to help the blind and visually impaired experience this year’s event. On Aug. 21, 2017, Kiki Smith’s teenage sons giddily prepared to watch the partial solar eclipse in Rochester, N.Y. As Ms. Smith listened to their chatter, she felt excluded.\n",
       "science_71  The rendezvous between the sun and the moon in 2017 captivated a small region in the Midwest. Lucky for Americans at the eclipse crossroads, they get to see it again. It is rare for a total solar eclipse to hit the same place twice — once every 366 years on average. In 2019, this happened in the Pacific Ocean, far west of the coast of Chile. By a stroke of luck, the next one will span a region of about 10,000 square miles that includes parts of southern Illinois, southeastern Missouri and western Kentucky."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allDocs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e687f-0552-4aea-a9ac-9a28de5d978a",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Convert to document-term matrix\n",
    "\n",
    "We will apply the CountVectorizer to convert our corpus into a document-term matrix. Empirical evidence has shown that simply counting words is more meaningful for performing LDA on documents. (It is possible to use the Tf-idf vectorizer too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9603ec70-34fe-4eda-8f4e-c75e891197b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4161269-702a-4006-9c43-d455bdece2fc",
   "metadata": {},
   "source": [
    "This process has always two steps: \n",
    "\n",
    "1. initialize the vectorizer constructor\n",
    "2. apply `fit_transform` to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a120ec0-4afc-4456-9e41-801cb7d0ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<234x4504 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8227 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b', # we want only words that contain letters and are 3 or more characters long\n",
    ")\n",
    "\n",
    "# Transform our data into the document-term matrix\n",
    "dtm = vectorizer.fit_transform(allDocs['document'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c49a6-0c86-4c3a-88fc-60416743329e",
   "metadata": {},
   "source": [
    "### Exploring the features   \n",
    "Let's look at the features of the \"model\", that is, the columns of our document-term matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5e9415-5d67-428e-a9f3-3a7cee7b453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abel', 'able', 'aboard', ..., 'zootampa', 'zumper', 'zuni'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd401a9-0ea4-408f-a59d-6fa33f5803f6",
   "metadata": {},
   "source": [
    "It's an array, let's look at its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21ea558-6a87-44e1-bd1b-f544df51fb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaeb888-ec28-4434-b1e2-f204a89c628e",
   "metadata": {},
   "source": [
    "Let's look at a larger chunk of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "394019cf-6cf7-4bf0-b506-30b0354b06de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['barge', 'bargoer', 'bargoers', 'barked', 'barley', 'barn', 'barr',\n",
       "       'barriers', 'bars', 'bartender', 'bartered', 'bartlett', 'based',\n",
       "       'basement', 'basic', 'basics', 'basil', 'basilica', 'basin',\n",
       "       'basmati', 'bass', 'bassin', 'batch', 'bath', 'bathroom',\n",
       "       'bathrooms', 'battle', 'bay', 'bays', 'beach', 'beaches', 'beads',\n",
       "       'bean', 'beans', 'beat', 'beau', 'beautiful', 'beauty', 'beckoned',\n",
       "       'bedford', 'bedrock', 'bedroom', 'bedrooms', 'beef', 'beefbars',\n",
       "       'beekman', 'beets', 'began', 'beginners', 'beginning'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[300:350]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8f6e5-cc38-44f4-8a52-07c458be436d",
   "metadata": {},
   "source": [
    "It's clear that these are all cleaned words, three or more characters long, which have not been stemmed. That is, we have both \"bean\" and \"beans\" as two separate features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441c6a9-b806-46dc-8d19-003138f74e1a",
   "metadata": {},
   "source": [
    "### Understanding the document-term matrix\n",
    "\n",
    "Let's look at a single row of the matrix, the first row, which corresponds to the first document from the NYT articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6860bb-fe49-4aec-be62-17f45d0b8ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4504 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = dtm[0]\n",
    "doc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b510de6-3055-489a-b391-d06cbcbfafe6",
   "metadata": {},
   "source": [
    "It says that it has 4504 colums, but there are only 32 stored elements (terms that are non-zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483867c7-fdbb-47a8-bc01-e638b36026ea",
   "metadata": {},
   "source": [
    "We can use some Python code to find the words and their counts for this document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d15978f-db56-4861-9c42-bb1d7b107fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bones: 1\n",
      "caramelized: 1\n",
      "chill: 1\n",
      "cold: 1\n",
      "commit: 1\n",
      "crisp: 1\n",
      "does: 1\n",
      "enveloped: 1\n",
      "fade: 1\n",
      "golden: 1\n",
      "happens: 1\n",
      "hard: 1\n",
      "heat: 1\n",
      "kindest: 1\n",
      "long: 1\n",
      "memory: 1\n",
      "method: 1\n",
      "middle: 1\n",
      "outside: 1\n",
      "oven: 1\n",
      "roast: 1\n",
      "soften: 1\n",
      "starts: 1\n",
      "stiff: 1\n",
      "stiffness: 1\n",
      "sweeten: 1\n",
      "tender: 2\n",
      "thing: 2\n",
      "vegetables: 2\n",
      "warmth: 1\n",
      "winter: 1\n",
      "year: 1\n"
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "doc_vec = dtm.getrow(row_index).toarray()\n",
    "\n",
    "non_zero_indices = doc_vec.nonzero()[1]\n",
    "dtm_scores = doc_vec[0, non_zero_indices] # goes and retrieves the values corresponding to the non_zero_indices\n",
    "words = [feature_names[i] for i in non_zero_indices]\n",
    "\n",
    "for word, score in zip(words, dtm_scores):\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ff9ed-95bf-4b9e-8548-bb834a2b1de6",
   "metadata": {},
   "source": [
    "We can look at non_zero_indices to check what that variable stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20535fab-52e4-4269-9381-c62f2fae8c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 437,  599,  713,  792,  830,  972, 1168, 1331, 1436, 1717, 1807,\n",
       "       1810, 1840, 2162, 2334, 2503, 2513, 2525, 2792, 2794, 3392, 3728,\n",
       "       3832, 3863, 3864, 3967, 4027, 4051, 4282, 4357, 4424, 4480],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765ac9d-fc51-42b3-baec-0f7ebb65ca9f",
   "metadata": {},
   "source": [
    "These values correspond to the column indices of each of the terms (words) in the matrix. A word like \"year\" has a high index, since is toward the end of the matrix, where terms are ordered alphabetically. \n",
    "\n",
    "Now that we know the indices of these words, we can use them to find how often each words occurrs in the entire matrix.\n",
    "\n",
    "We will check the word \"caramelized\", which has the index 599."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "635fcf0d-bbfe-4760-a952-fd9e2f4d5c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.getcol(599).toarray().T # get the column, turn it into an array format, then transpose it to be a row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06004ee-0ad3-4285-8133-adfbf4d8ab8e",
   "metadata": {},
   "source": [
    "It's obvious that the word doesn't show up often, I see only 3 values of 1. Let's check for the word \"vegetables\", index = 4282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a156328-75b8-436c-91b9-5db2411f7b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.getcol(4282).toarray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4c44f-01da-41a8-aba4-2b121f85a5aa",
   "metadata": {},
   "source": [
    "Even this word doesn't show in more than 3 documents in total. Meanwhile, let's see a word like \"year\", index = 4480:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3170843d-0df9-49e0-b941-34ffa9659ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.getcol(4480).toarray().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432d6ba-2f86-4d06-9b9e-a1ba793774ef",
   "metadata": {},
   "source": [
    "This seems to occur a bit more often, we can find in how many documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5935a083-f208-433a-bd25-5d371e105eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(dtm.getcol(4480).toarray().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3078b-a018-457c-8eab-6a0107a1cf42",
   "metadata": {},
   "source": [
    "### **Task for you:** find the top 5 words from this document (meaning, they show in most articles).\n",
    "\n",
    "Use the variable names that have been seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a8bdb-96dc-4cb7-af3b-170f6d29cef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cabef82-eeb1-48a6-af28-aa7f576609e2",
   "metadata": {},
   "source": [
    "**Reflection questions** \n",
    "\n",
    "1. From these top words would you be able to infer that this document is about cooking/food? \n",
    "\n",
    "2. If these words were part of a **topic**, what would you name that topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf11f7-ec50-44ff-ad6a-553fb67e80db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7574965-face-42cd-a7e7-4b91cdb9ee5f",
   "metadata": {},
   "source": [
    "### Going back to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c44efe-ee5f-40f8-aa8d-988ab464ceec",
   "metadata": {},
   "source": [
    "We can create a function that takes the representation of each document as a row of numbers in the matrix and converts it back to a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d3de9-d4ce-4674-b832-6b36da164b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2Doc(dtMatrix, features, index):\n",
    "    \"\"\"Turns each row of the document-term matrix into a list of terms\"\"\"\n",
    "    row = dtMatrix.getrow(index).toarray()\n",
    "    non_zero_indices = row.nonzero()[1]\n",
    "    words = [features[idx] for idx in non_zero_indices]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41e469-d996-4595-9d7d-37e799206555",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocsAsTerms = [matrix2Doc(dtm, feature_names, i) for i in range(dtm.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba40d9d-9587-479d-a496-c7057c3072ab",
   "metadata": {},
   "source": [
    "Check that we have all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e28bb-0490-475a-ac94-81fc5e4e9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allDocsAsTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d29b95-d2b4-49d0-8a3a-e91c849cddda",
   "metadata": {},
   "source": [
    "Add a column to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c44a4-ebf2-4bad-9008-050d4af37769",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs['terms'] = allDocsAsTerms\n",
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba34c1-e132-447c-9304-f084af84e8ff",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## 3. Fit the LDA model\n",
    "\n",
    "Now that the data is ready and we understand well how it is represented (and how sparse it is), let us fit the LDA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6632eb57-7a22-4e3c-9a6a-8615859147ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LatentDirichletAllocation<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=15, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=15, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Initialize the model\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=15, # we are picking the number of topics arbitrarely at the moment\n",
    "                                random_state=0)\n",
    "\n",
    "# Step 2: Fit the model\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6995b3-15d9-42de-a289-f1f797a18cbc",
   "metadata": {},
   "source": [
    "The representation of topics can be accessed this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa59e523-b7bd-418e-a7f6-17bd6a59f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 1.06666664,\n",
       "        0.06666667],\n",
       "       [0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 0.06666667,\n",
       "        0.06666667],\n",
       "       [0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 0.06666667,\n",
       "        2.06666667],\n",
       "       ...,\n",
       "       [0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 0.06666667,\n",
       "        0.06666667],\n",
       "       [0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 0.06666667,\n",
       "        0.06666667],\n",
       "       [0.06666667, 0.06666667, 0.06666667, ..., 0.06666667, 0.06666667,\n",
       "        0.06666667]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a4970-0d1f-4272-9f85-ec7a594ad549",
   "metadata": {},
   "source": [
    "What are the dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa1ab118-d07e-4d26-8b26-fea7e06fea87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4504)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1e132-5d4b-42b5-bce2-46797d18e222",
   "metadata": {},
   "source": [
    "So, this is a 15 by 4504 matrix, where each row is one of our topics and each column is a word (term). The values that we see are **not** probabilities, they are the **parameters** fitted by the LDA model for the topic-term distribution. We can see that they are not probabilities, since at least some of them seem to have a value > 1. \n",
    "\n",
    "These values are so-called \"pseudo-counts\" that reflect how many times, probabilistically speaking, each word was assigned to each topic across the entire corpus, adjusted by the model's learning process. The values are proportional to the probability of a term given a topic, but they need to be normalized to sum to one across each row to represent actual probabilities.\n",
    "\n",
    "Now that we have such a **topic-term distribution**, we can find the top words associated with each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b87bc6dd-7180-426f-b289-ae47c3534a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "moon home world years major built spacecraft head year ago way place skaters champion include\n",
      "Topic 1:\n",
      "new city dining home restaurants year house space said restaurant built program years make victorian\n",
      "Topic 2:\n",
      "eclipse chicken restaurants new time built monday family home square near place moon style hard\n",
      "Topic 3:\n",
      "new rent apartment make building bedroom halloumi home biscuits work century time minute best high\n",
      "Topic 4:\n",
      "eggs home just easy sweet people early outside needs park probably day better founded cooking\n",
      "Topic 5:\n",
      "home sellers realtors estate real chicken group pay association new national said commissions lawsuits brought\n",
      "Topic 6:\n",
      "home bread kenji buy south american ago restaurant drive day species dishes years questions art\n",
      "Topic 7:\n",
      "bedroom room properties house space week new com bath kitchen half dining floor basement living\n",
      "Topic 8:\n",
      "family home salmon flour near recipe make leeks new work died like just small lower\n",
      "Topic 9:\n",
      "new home national united bedroom work science just earth year states better quarter couple foundation\n",
      "Topic 10:\n",
      "like new spring cooking winter york clubs recipe day dinner cancer culture chicken taste raisins\n",
      "Topic 11:\n",
      "sheet pan new eggs meal dog chicken city just like recipes people bird skillet dinner\n",
      "Topic 12:\n",
      "new birds known sea low heavy area rocket nunhead restore delta brooklyn rare common researchers\n",
      "Topic 13:\n",
      "bond trees years mortgage year company lease new old food ago say rent northern mall\n",
      "Topic 14:\n",
      "new study family percent estate real home bacon don recent agents rice single suggests budget\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-no_top_words-1:-1]])) # syntax for reversing a list [::-1]\n",
    "\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2afd9-7baf-4603-a19d-b5f72b7de0c4",
   "metadata": {},
   "source": [
    "**To note:** Looking at these words, it is hard to decide what topic each of them represents since words about food, realestate, and science are mixed together in each topic. Topic 11 seems relatively homogenous, it's clear that it is talking about food. \n",
    "\n",
    "Knowing how sparse our document-term matrix was (only 234 documents, but 4504 terms) it is to be expected that there isn't enough data to learn a better model that captures better topics (and the words associated with them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a344c-b155-4fcf-b9e9-5c7c42e7ea3a",
   "metadata": {},
   "source": [
    "### The document-topic matrix and dominant topics\n",
    "\n",
    "In the prior step, by fitting the LDA model, we found the topics that are present in our corpus. Now, we will use these topics to generate the documents. For that, we will use the method `transform`. This method will transform our document-term matrix into a new matrix, the document-topic matrix. This is where the **dimensionality reduction** is happening. We go from the large document-term matrix to a narrow document-topic matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f67ac43e-6658-491e-8780-55bcf4cc5f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.85185343e-03, 1.85185310e-03, 1.85185415e-03, ...,\n",
       "        1.85185194e-03, 1.85185449e-03, 1.85185232e-03],\n",
       "       [1.25786180e-03, 9.82389927e-01, 1.25786235e-03, ...,\n",
       "        1.25786176e-03, 1.25786520e-03, 1.25786206e-03],\n",
       "       [8.13008233e-04, 8.13008358e-04, 8.13008488e-04, ...,\n",
       "        8.13008322e-04, 8.13008332e-04, 8.13008816e-04],\n",
       "       ...,\n",
       "       [2.29885068e-03, 2.29885189e-03, 2.29885136e-03, ...,\n",
       "        9.67816078e-01, 2.29885078e-03, 2.29885116e-03],\n",
       "       [2.29885133e-03, 9.67816079e-01, 2.29885285e-03, ...,\n",
       "        2.29885289e-03, 2.29885103e-03, 2.29885086e-03],\n",
       "       [1.58730305e-03, 1.58730257e-03, 9.77777766e-01, ...,\n",
       "        1.58730338e-03, 1.58730263e-03, 1.58730230e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist = lda.transform(dtm)\n",
    "doc_topic_dist "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5530a8-aee2-45c1-94ac-c8ab708f8f64",
   "metadata": {},
   "source": [
    "Verify the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b9ce858-523f-4005-8efc-63c2a3b1b4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d732cc5-9f68-426f-88b7-e2fb29532747",
   "metadata": {},
   "source": [
    "**Meaning of the matrix values:** The entries in this matrix represent the proportion of the document's content that is attributed to each topic. This means each row of the output matrix is a distribution over topics for the corresponding document and should sum to one. We can easily test that by getting the sum of a row:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7240d-4f78-4d25-af41-91652de7c104",
   "metadata": {},
   "source": [
    "**Better representing the document-topic matrix**\n",
    "\n",
    "The document-topic matrix above is not very legible, we will create a dataframe that has a better representation. First, I'll modify the function `display_topics` to show a few terms for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4a1f92-6803-4591-ae61-dabdf3bdb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayHeader(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    topicNames = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicNames.append(f\"Topic {topic_idx}: \" + (\", \".join([features[i]\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])))\n",
    "    return topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96371208-d821-4f08-8e13-3a148df7dc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0: moon, home, world, years, major</th>\n",
       "      <th>Topic 1: new, city, dining, home, restaurants</th>\n",
       "      <th>Topic 2: eclipse, chicken, restaurants, new, time</th>\n",
       "      <th>Topic 3: new, rent, apartment, make, building</th>\n",
       "      <th>Topic 4: eggs, home, just, easy, sweet</th>\n",
       "      <th>Topic 5: home, sellers, realtors, estate, real</th>\n",
       "      <th>Topic 6: home, bread, kenji, buy, south</th>\n",
       "      <th>Topic 7: bedroom, room, properties, house, space</th>\n",
       "      <th>Topic 8: family, home, salmon, flour, near</th>\n",
       "      <th>Topic 9: new, home, national, united, bedroom</th>\n",
       "      <th>Topic 10: like, new, spring, cooking, winter</th>\n",
       "      <th>Topic 11: sheet, pan, new, eggs, meal</th>\n",
       "      <th>Topic 12: new, birds, known, sea, low</th>\n",
       "      <th>Topic 13: bond, trees, years, mortgage, year</th>\n",
       "      <th>Topic 14: new, study, family, percent, estate</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food_1</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic 0: moon, home, world, years, major  \\\n",
       "food_1                                     0.002   \n",
       "food_2                                     0.001   \n",
       "food_3                                     0.001   \n",
       "food_4                                     0.002   \n",
       "food_5                                     0.001   \n",
       "\n",
       "        Topic 1: new, city, dining, home, restaurants  \\\n",
       "food_1                                          0.002   \n",
       "food_2                                          0.982   \n",
       "food_3                                          0.001   \n",
       "food_4                                          0.002   \n",
       "food_5                                          0.001   \n",
       "\n",
       "        Topic 2: eclipse, chicken, restaurants, new, time  \\\n",
       "food_1                                              0.002   \n",
       "food_2                                              0.001   \n",
       "food_3                                              0.001   \n",
       "food_4                                              0.002   \n",
       "food_5                                              0.001   \n",
       "\n",
       "        Topic 3: new, rent, apartment, make, building  \\\n",
       "food_1                                          0.002   \n",
       "food_2                                          0.001   \n",
       "food_3                                          0.001   \n",
       "food_4                                          0.978   \n",
       "food_5                                          0.001   \n",
       "\n",
       "        Topic 4: eggs, home, just, easy, sweet  \\\n",
       "food_1                                   0.974   \n",
       "food_2                                   0.001   \n",
       "food_3                                   0.001   \n",
       "food_4                                   0.002   \n",
       "food_5                                   0.001   \n",
       "\n",
       "        Topic 5: home, sellers, realtors, estate, real  \\\n",
       "food_1                                           0.002   \n",
       "food_2                                           0.001   \n",
       "food_3                                           0.001   \n",
       "food_4                                           0.002   \n",
       "food_5                                           0.001   \n",
       "\n",
       "        Topic 6: home, bread, kenji, buy, south  \\\n",
       "food_1                                    0.002   \n",
       "food_2                                    0.001   \n",
       "food_3                                    0.001   \n",
       "food_4                                    0.002   \n",
       "food_5                                    0.001   \n",
       "\n",
       "        Topic 7: bedroom, room, properties, house, space  \\\n",
       "food_1                                             0.002   \n",
       "food_2                                             0.001   \n",
       "food_3                                             0.001   \n",
       "food_4                                             0.002   \n",
       "food_5                                             0.001   \n",
       "\n",
       "        Topic 8: family, home, salmon, flour, near  \\\n",
       "food_1                                       0.002   \n",
       "food_2                                       0.001   \n",
       "food_3                                       0.989   \n",
       "food_4                                       0.002   \n",
       "food_5                                       0.001   \n",
       "\n",
       "        Topic 9: new, home, national, united, bedroom  \\\n",
       "food_1                                          0.002   \n",
       "food_2                                          0.001   \n",
       "food_3                                          0.001   \n",
       "food_4                                          0.002   \n",
       "food_5                                          0.001   \n",
       "\n",
       "        Topic 10: like, new, spring, cooking, winter  \\\n",
       "food_1                                         0.002   \n",
       "food_2                                         0.001   \n",
       "food_3                                         0.001   \n",
       "food_4                                         0.002   \n",
       "food_5                                         0.001   \n",
       "\n",
       "        Topic 11: sheet, pan, new, eggs, meal  \\\n",
       "food_1                                  0.002   \n",
       "food_2                                  0.001   \n",
       "food_3                                  0.001   \n",
       "food_4                                  0.002   \n",
       "food_5                                  0.982   \n",
       "\n",
       "        Topic 12: new, birds, known, sea, low  \\\n",
       "food_1                                  0.002   \n",
       "food_2                                  0.001   \n",
       "food_3                                  0.001   \n",
       "food_4                                  0.002   \n",
       "food_5                                  0.001   \n",
       "\n",
       "        Topic 13: bond, trees, years, mortgage, year  \\\n",
       "food_1                                         0.002   \n",
       "food_2                                         0.001   \n",
       "food_3                                         0.001   \n",
       "food_4                                         0.002   \n",
       "food_5                                         0.001   \n",
       "\n",
       "        Topic 14: new, study, family, percent, estate  dominant_topic  \n",
       "food_1                                          0.002               4  \n",
       "food_2                                          0.001               1  \n",
       "food_3                                          0.001               8  \n",
       "food_4                                          0.002               3  \n",
       "food_5                                          0.001              11  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "topicnames = displayHeader(lda, feature_names, 5)\n",
    "\n",
    "# index names\n",
    "docnames = allDocs.index.tolist() # We will use the original names of the documents\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(doc_topic_dist, 3), \n",
    "                                 columns=topicnames, \n",
    "                                 index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1) # finds the maximum argument\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abe294-73e9-4649-a6b3-1a6613398753",
   "metadata": {},
   "source": [
    "Let's look at some documents between food and realestate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8533f72c-1c5f-4693-ba3e-6339634bc801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0: moon, home, world, years, major</th>\n",
       "      <th>Topic 1: new, city, dining, home, restaurants</th>\n",
       "      <th>Topic 2: eclipse, chicken, restaurants, new, time</th>\n",
       "      <th>Topic 3: new, rent, apartment, make, building</th>\n",
       "      <th>Topic 4: eggs, home, just, easy, sweet</th>\n",
       "      <th>Topic 5: home, sellers, realtors, estate, real</th>\n",
       "      <th>Topic 6: home, bread, kenji, buy, south</th>\n",
       "      <th>Topic 7: bedroom, room, properties, house, space</th>\n",
       "      <th>Topic 8: family, home, salmon, flour, near</th>\n",
       "      <th>Topic 9: new, home, national, united, bedroom</th>\n",
       "      <th>Topic 10: like, new, spring, cooking, winter</th>\n",
       "      <th>Topic 11: sheet, pan, new, eggs, meal</th>\n",
       "      <th>Topic 12: new, birds, known, sea, low</th>\n",
       "      <th>Topic 13: bond, trees, years, mortgage, year</th>\n",
       "      <th>Topic 14: new, study, family, percent, estate</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food_77</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_78</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_79</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_80</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food_81</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_1</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_3</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_4</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realestate_5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.145</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic 0: moon, home, world, years, major  \\\n",
       "food_77                                          0.002   \n",
       "food_78                                          0.006   \n",
       "food_79                                          0.001   \n",
       "food_80                                          0.002   \n",
       "food_81                                          0.001   \n",
       "realestate_1                                     0.002   \n",
       "realestate_2                                     0.005   \n",
       "realestate_3                                     0.963   \n",
       "realestate_4                                     0.963   \n",
       "realestate_5                                     0.001   \n",
       "\n",
       "              Topic 1: new, city, dining, home, restaurants  \\\n",
       "food_77                                               0.002   \n",
       "food_78                                               0.006   \n",
       "food_79                                               0.001   \n",
       "food_80                                               0.002   \n",
       "food_81                                               0.001   \n",
       "realestate_1                                          0.002   \n",
       "realestate_2                                          0.005   \n",
       "realestate_3                                          0.003   \n",
       "realestate_4                                          0.003   \n",
       "realestate_5                                          0.001   \n",
       "\n",
       "              Topic 2: eclipse, chicken, restaurants, new, time  \\\n",
       "food_77                                                   0.002   \n",
       "food_78                                                   0.006   \n",
       "food_79                                                   0.001   \n",
       "food_80                                                   0.002   \n",
       "food_81                                                   0.001   \n",
       "realestate_1                                              0.002   \n",
       "realestate_2                                              0.005   \n",
       "realestate_3                                              0.003   \n",
       "realestate_4                                              0.003   \n",
       "realestate_5                                              0.001   \n",
       "\n",
       "              Topic 3: new, rent, apartment, make, building  \\\n",
       "food_77                                               0.002   \n",
       "food_78                                               0.006   \n",
       "food_79                                               0.001   \n",
       "food_80                                               0.002   \n",
       "food_81                                               0.001   \n",
       "realestate_1                                          0.972   \n",
       "realestate_2                                          0.005   \n",
       "realestate_3                                          0.003   \n",
       "realestate_4                                          0.003   \n",
       "realestate_5                                          0.001   \n",
       "\n",
       "              Topic 4: eggs, home, just, easy, sweet  \\\n",
       "food_77                                        0.002   \n",
       "food_78                                        0.915   \n",
       "food_79                                        0.984   \n",
       "food_80                                        0.002   \n",
       "food_81                                        0.001   \n",
       "realestate_1                                   0.002   \n",
       "realestate_2                                   0.005   \n",
       "realestate_3                                   0.003   \n",
       "realestate_4                                   0.003   \n",
       "realestate_5                                   0.001   \n",
       "\n",
       "              Topic 5: home, sellers, realtors, estate, real  \\\n",
       "food_77                                                0.002   \n",
       "food_78                                                0.006   \n",
       "food_79                                                0.001   \n",
       "food_80                                                0.002   \n",
       "food_81                                                0.001   \n",
       "realestate_1                                           0.002   \n",
       "realestate_2                                           0.005   \n",
       "realestate_3                                           0.003   \n",
       "realestate_4                                           0.003   \n",
       "realestate_5                                           0.001   \n",
       "\n",
       "              Topic 6: home, bread, kenji, buy, south  \\\n",
       "food_77                                         0.002   \n",
       "food_78                                         0.006   \n",
       "food_79                                         0.001   \n",
       "food_80                                         0.002   \n",
       "food_81                                         0.001   \n",
       "realestate_1                                    0.002   \n",
       "realestate_2                                    0.005   \n",
       "realestate_3                                    0.003   \n",
       "realestate_4                                    0.003   \n",
       "realestate_5                                    0.001   \n",
       "\n",
       "              Topic 7: bedroom, room, properties, house, space  \\\n",
       "food_77                                                  0.002   \n",
       "food_78                                                  0.006   \n",
       "food_79                                                  0.001   \n",
       "food_80                                                  0.002   \n",
       "food_81                                                  0.001   \n",
       "realestate_1                                             0.002   \n",
       "realestate_2                                             0.005   \n",
       "realestate_3                                             0.003   \n",
       "realestate_4                                             0.003   \n",
       "realestate_5                                             0.001   \n",
       "\n",
       "              Topic 8: family, home, salmon, flour, near  \\\n",
       "food_77                                            0.973   \n",
       "food_78                                            0.006   \n",
       "food_79                                            0.001   \n",
       "food_80                                            0.002   \n",
       "food_81                                            0.001   \n",
       "realestate_1                                       0.002   \n",
       "realestate_2                                       0.928   \n",
       "realestate_3                                       0.003   \n",
       "realestate_4                                       0.003   \n",
       "realestate_5                                       0.001   \n",
       "\n",
       "              Topic 9: new, home, national, united, bedroom  \\\n",
       "food_77                                               0.002   \n",
       "food_78                                               0.006   \n",
       "food_79                                               0.001   \n",
       "food_80                                               0.002   \n",
       "food_81                                               0.983   \n",
       "realestate_1                                          0.002   \n",
       "realestate_2                                          0.005   \n",
       "realestate_3                                          0.003   \n",
       "realestate_4                                          0.003   \n",
       "realestate_5                                          0.001   \n",
       "\n",
       "              Topic 10: like, new, spring, cooking, winter  \\\n",
       "food_77                                              0.002   \n",
       "food_78                                              0.006   \n",
       "food_79                                              0.001   \n",
       "food_80                                              0.965   \n",
       "food_81                                              0.001   \n",
       "realestate_1                                         0.002   \n",
       "realestate_2                                         0.005   \n",
       "realestate_3                                         0.003   \n",
       "realestate_4                                         0.003   \n",
       "realestate_5                                         0.001   \n",
       "\n",
       "              Topic 11: sheet, pan, new, eggs, meal  \\\n",
       "food_77                                       0.002   \n",
       "food_78                                       0.006   \n",
       "food_79                                       0.001   \n",
       "food_80                                       0.002   \n",
       "food_81                                       0.001   \n",
       "realestate_1                                  0.002   \n",
       "realestate_2                                  0.005   \n",
       "realestate_3                                  0.003   \n",
       "realestate_4                                  0.003   \n",
       "realestate_5                                  0.001   \n",
       "\n",
       "              Topic 12: new, birds, known, sea, low  \\\n",
       "food_77                                       0.002   \n",
       "food_78                                       0.006   \n",
       "food_79                                       0.001   \n",
       "food_80                                       0.002   \n",
       "food_81                                       0.001   \n",
       "realestate_1                                  0.002   \n",
       "realestate_2                                  0.005   \n",
       "realestate_3                                  0.003   \n",
       "realestate_4                                  0.003   \n",
       "realestate_5                                  0.001   \n",
       "\n",
       "              Topic 13: bond, trees, years, mortgage, year  \\\n",
       "food_77                                              0.002   \n",
       "food_78                                              0.006   \n",
       "food_79                                              0.001   \n",
       "food_80                                              0.002   \n",
       "food_81                                              0.001   \n",
       "realestate_1                                         0.002   \n",
       "realestate_2                                         0.005   \n",
       "realestate_3                                         0.003   \n",
       "realestate_4                                         0.003   \n",
       "realestate_5                                         0.839   \n",
       "\n",
       "              Topic 14: new, study, family, percent, estate  dominant_topic  \n",
       "food_77                                               0.002               8  \n",
       "food_78                                               0.006               4  \n",
       "food_79                                               0.001               4  \n",
       "food_80                                               0.002              10  \n",
       "food_81                                               0.001               9  \n",
       "realestate_1                                          0.002               3  \n",
       "realestate_2                                          0.005               8  \n",
       "realestate_3                                          0.003               0  \n",
       "realestate_4                                          0.003               0  \n",
       "realestate_5                                          0.145              13  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic[76:86]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5325654-87ca-413b-8575-2d0e017f39ea",
   "metadata": {},
   "source": [
    "One interesting thing here is that articles food_78 and food_79 seem to share the dominant topic, just like realestate_1 and realestate_2. Interestingly, realestate_5 has two topics with value > 0.1, both of which seem to be primarely about real estate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2294d8f-d75d-409f-94fc-8600890ef120",
   "metadata": {},
   "source": [
    "### Topic distribution across documents\n",
    "\n",
    "Now that we have the document-topic matrix, we can see which topics show up most frequently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b6d83-982f-4214-a09d-719ce7076fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3071b0-4bf2-4dc8-b805-ad060d93546b",
   "metadata": {},
   "source": [
    "### Challenge yourself: Add two more columns\n",
    "\n",
    "Using your pandas skills add two new columns to this dataframe:\n",
    "\n",
    "1. a column with the top 10 words of the corresponding topic. (see Topic Num for the topic number)\n",
    "2. a column that lists the document names associated with the topic (document names are things like food_1, food_2, etc.)\n",
    "\n",
    "By adding these two columns it will be a bit easier to understand what is going one with the model and whether it is capturing something about the corpus of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8067b54-8ddd-4715-a8a2-75d07369491d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ee5a5e5-80c0-488c-9a0c-b2286009393e",
   "metadata": {},
   "source": [
    "### Interpretation Task\n",
    "\n",
    "Pick a topic that doesn't have many documents assigned to it and then read all the articles (see dataframe at the start of the notebook) associated with this topic. Do you see any reason for why they were given the same dominant topic? Can you summarize in a single phrase what the meaning of that topic is? (Also make use of the top 15 words for that topic.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04a71b-ced1-435d-b4ba-8dc003c8675f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a872c0-923b-4c7f-9afb-cd05455cc901",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "## 4. Grid Search: Find number of topics\n",
    "\n",
    "In the example so far, we arbitrarely chose the number of topics to be 15. However, that is not the right way to go about it. We whould use methods for selecting the optimal number of topics. This can be done through a mechanism known as GridSearch with cross-validation that builds multiple models and then compares them to see which one performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e66c50-a2da-4a3d-a6ca-90ee1ab576b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We are going to test multiple values for the number of topics\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Initialize a Grid Search with cross-validation instance\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "grid.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf126a6-327f-4a89-9b37-c2cf483c987c",
   "metadata": {},
   "source": [
    "Let us look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a55148-df6e-42ba-b11d-2cd2179f2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412e2f6-56d8-4b82-a667-5b934a0ea374",
   "metadata": {},
   "source": [
    "Since this representation is a bit overwhelming, let's access a few features of the grid instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a27fe7-3704-43a4-beea-69d5898d00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ede5a-61a2-40fc-95c0-1272f3e39c76",
   "metadata": {},
   "source": [
    "The results are showing that the best LDA model should have 5 topics, the smallest number we tried. This raises the question of whether we should try other small numbers, which I'm doing below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ff1e3-c05c-48eb-85c8-2c55979d00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': [1,2,3,4,5,6]}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "grid.fit(dtm)\n",
    "\n",
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43140116-4981-40ae-a3f5-b3a3968fc7a1",
   "metadata": {},
   "source": [
    "This result shows that actually the best number of topics for this corpus is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad0057-13ff-4bd1-8697-f4d94c24be0e",
   "metadata": {},
   "source": [
    "**Meaning of Log Likelihood**. \n",
    "\n",
    "Log Likelihood is the logarithm of the probability of observing the given data under the model with specific parameters. Essentially, it measures how well the model explains the observed data. (It is a conditional probability.)\n",
    "\n",
    "**Meaning of perplexity**\n",
    "\n",
    "Perplexity is a common metric used to evaluate the quality of probabilistic models. It reflects how well the model describes or predicts the documents in the dataset.\n",
    "\n",
    "A lower perplexity score suggests that the model is more certain about its predictions (i.e., the probability distributions it assigns to unseen documents are more accurate). This means that the topic distributions learned by the model are a good fit for the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d0ca2-e901-498b-9555-36906db69ffe",
   "metadata": {},
   "source": [
    "**Words for best modesl with one topic**\n",
    "\n",
    "Let's see what are the top words for the best model with one topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b987c2-8a89-4576-b876-ef434a14c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(best_lda_model, feature_names, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20193f66-1255-49c4-acda-146fc9407c4e",
   "metadata": {},
   "source": [
    "As we can see it is a mix of food and realestae and New York. If we had documents with more distinct nature and more of them we might have seen something else. \n",
    "\n",
    "However, the point of this tutorial was to show the mechanics of building LDA models. \n",
    "\n",
    "Now it's time to take what you saw here and apply it to your projects.\n",
    "\n",
    "Have fun exploring!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94654-fe6b-43d6-b1a2-873e589e9e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
